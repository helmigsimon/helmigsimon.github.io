{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "With this blog I want to create a running journal of my thoughts, recommendations and work related to the two pursuits I spend most of my time on nowadays, namely programming in Python and practicing Machine Learning. I hope to use this platform first as a means of synthesizing my own learning & tracking my progress and secondly as a way to curate a selection of insights into the aforementioned topics that may help fellow learners and pique the interest of other enthusiasts. It’s with this goal in mind that I’ve named this blog “Human Learning Algorithm”, as a perhaps slightly contrived nod to both the subject matter of the page and the development of my own understanding of this space.\n",
    "\n",
    "To set the stage for future posts, I'd like to use the rest of this one productively, by highlighting some useful sources of information on Python and Machine Learning that have been key in shaping my understanding of both of these topics. While not an exhaustive list of material, the following quickly came to mind as being particularly relevant for any readers also interested in the theme of this blog."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Books\n",
    "### The Hundred Page Machine Learning Book - Andriy Burkov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Link: http://themlbook.com/**\n",
    "\n",
    "Andriy Burkov's 'The Hundred Page Machine Learning Book\" is a concise survey of the contemporary landscape of Machine Learning, and a great read for both the uninitiated, as well as the seasoned veterans of field. I found Burkov's explanations of core learning algorithms to be a fantastic introduction for people who are still slightly unsure about what a “Recurrent Neural Network” is, but also want to get an initial insight into some of the mathematics behind it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow - Aurélien Géron\n",
    "**Link: https://www.oreilly.com/library/view/hands-on-machine-learning/9781492032632/**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'll confess that I have not actually finished this book yet, but it warrants a mention nonetheless. *Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow* is routinely highlighted as one of the best top-down introductions to Machine Learning in Python and was recently called a \"masterpiece\" by Tim O'Reilly (despite his skin in the game as the publisher of this book, I think his comment still speaks volumes about *Hands-On*, given the sheer size  and quality of *O'Reilly Media*'s back catalogue). When I started reading this book, I was impressed with how concisely and cohesively Géron manages to bring core concepts across, and once I have some more time on my hands, I will be sure to go through it in it's entirety."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Podcasts\n",
    "### Artificial Intelligence\n",
    "**Link: https://lexfridman.com/ai/**\n",
    "\n",
    "The *Artificial Intelligence* podcast is arguably the best in the world right now. For individuals interested in Artificial Intelligence and Machine Learning, it offers an unbeatable lineup of discussions with the field's key movers and shakers. As of late, Lex Fridman, the host of *Artifical Intelligence* and Research Scientist at MIT, has even expanded the purview of the podcast and now often features luminaries from all walks of life, including neuroscientists, linguists, historians, economists, educators and comedians, alongside the computer scientists instrumental to the field of Artificial Intelligence. Some notable guests of the podcast include Yoshua Bengio, Yann LeCun, Elon Musk, Noam Chomsky, Guido van Rossum, Paul Krugman, Donald Knuth and Ian Goodfellow, among many other brilliant people.\n",
    "\n",
    "### Linear Digressions \n",
    "**Link: https://lineardigressions.com/**\n",
    "\n",
    "When it comes to podcasts in the ML/AI space, my experience has been that many focus either on the higher-level debates that surround the field, such as the aforementioned *Artificial Intelligence* podcast, or fairly specific applications of the technology in industry and academia. *Linear Digressions* fits a very different niche, with each episode featuring its hosts, Katie (a Data Scientist) and Ben (a Web Developer),  diving into some topic related to Data Science and Machine Learning for about 20 minutes. Some of my favorite episodes include  “Federated Learning”, “Word2Vec”, “Quantile Regression” and “How to Lose at Kaggle”. The exchanges between the hosts are easy-going and enjoyable to listen to, and are great for both topic review and discovery."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Twitter Feeds\n",
    "### Jeremy Howard\n",
    "**Link: https://twitter.com/jeremyphoward**\n",
    "\n",
    "Jeremy Howard is the co-founder of fast.ai, a research group offering education through online courses, software such as the fastai and nbdev libraries, and commentary on the current state of the field of AI from an ethical perspective. His approach to education, research and development is highly applied and results-driven, which results in a refreshingly practical perspective in a space that is unsurprisingly often fairly academic.  The fruits of his labor even include this blog, as I have set it up using the *fast_template* repository he made available just a few days ago. His Twitter feed is a great way to keep up with the contemporary state of the field of AI, and in particular with what deep learning methods are currently bringing the best results for those of us that don't have dozens of GPUs at the ready.\n",
    "\n",
    "### Francois Chollet\n",
    "**Link: https://twitter.com/fchollet**\n",
    "\n",
    "Francois Chollet is an AI Researcher and Software Engineer at Google, and is perhaps most well known for his authorship of the Keras Library and the book, “Deep Learning with Python”. Even before becoming a fan of Keras, I was introduced to Chollet through his appearance on the *Artificial Intelligence* podcast, in which he deeply impressed me with his case against the idea of an inevitable \"intelligence explosion” taking place as the field of AI progresses. The first principles approach he so often takes on contentious issues is highly inspiring, and is on full display in his recent paper *On The Measure of Intelligence*, in which he presents a new formal definition of intelligence, as well as the Abstraction and Reasoning Corpus (ARC), a benchmark designed to measure general fluid intelligence and enable effective intelligence comparisons between AI systems and ourselves. If you enjoy his software, commentary or research, I highly recommend following him on Twitter, as he doesn't seem to run out of insightful takes on issues related to his field of study."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Articles\n",
    "### Coding Habits for Data Scientists\n",
    "**Link: https://www.thoughtworks.com/insights/blog/coding-habits-data-scientists**\n",
    "\n",
    "This article was truly eye-opening for me as a self-taught programmer. Even if you’ve heard of the SOLID principles and try to write “Clean Code” as much as possible, it is difficult to truly understand what implementing the single responsibility principle looks like in practice until you’ve actually seen it. While this article is not a comprehensive guide on the subject, and is certainly not a perfect substitute for reading Uncle Bob’s book, it’s a great way to quickly identify if you’ve been developing some habits you could probably do without. \n",
    "\n",
    "### Python Logging: An In-Depth Tutorial\n",
    "**Link: https://www.toptal.com/python/in-depth-python-logging**\n",
    "\n",
    "Once I figured out what logging was and how it could be implemented in code, I became an instant convert to the practice. The number of times it has saved me what would likely have otherwise been hours of debugging at my day job have been countless. For those looking for an introduction on how to best attack logging in Python, I highly recommend this piece, and in particular the implementation that is made available at the end of the article, which has been far more useful for me than other slightly less straightforward implementations you’ll find online occasionally. In a future blog post I'll share my preferred way of integrating logging into my programs, which makes use of this article's implementation, as well as its insights more generally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Platform\n",
    "\n",
    "### DrivenData\n",
    "**Link: https://www.drivendata.org**\n",
    "\n",
    "During university I worked part-time for a student-run management consultancy focusing on providing advisory work for sustainable start-ups in Switzerland (check them out at www.studentimpact.ch). Ever since, I’ve become personally invested in social and ecological sustainability, and in my fledgling passion for Data Science, I’ve managed to find a platform which combines both of these interests: DrivenData. The DrivenData team leverage crowdsourcing by hosting Data Science competitions (à la Kaggle) to help tackle some of the world's biggest social challenges. Currently, they have competitions open related to the analysis of tabular and image data, for use cases such as the prediction of earthquake damage in Nepal, the prediction of the spread of dengue fever in Central & South America and the segmentation of buildings for disaster resilience in Africa. I’m very excited to dive into this platform in the months to come!\n",
    "\n",
    "I hope I’ve been able to point out some resources you did not previously have on your radar, and hope you’ll come back for my next post, in which I’ll be summing up my experiences and takeaways from the Applied Machine Learning Conference in Lausanne!\n",
    "\n",
    "Simon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
