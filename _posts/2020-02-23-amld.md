
# Title
> summary


# The Applied Machine Learning Days In Review

*Source: https://twitter.com/appliedmldays/header_photo*

I recently had the opportunity to attend the Applied Machine Learning Days Conference in Lausanne, where I spent five days participating in workshops and attending  talks by researchers and industry leaders in the field of Machine Learning. With this post I would like to share my impressions from the event and reflect on some of my personal highlights from the event.

# Workshops

## Unsupervised Fraud Detection by Julius Bär
The first workshop of the event was also one of the most engaging I had the opportunity to attend at the Applied Machine Learning Days. The workshop by Julius Bär's Data Science team focused on giving a hands-on introduction to the way in which unsupervised learning techniques can help in the fight against fraud in the financial services industry, which they reported to be estimated to cost companies worldwide around 7% of their total expenditures. After reviewing the key algorithms used for outlier detection work (in particular, KNN, LOF, PCA, Isolation Forests and Autoencoders) and applying them in an excercise, we were invited take part in the culminating challenge exercise of the workshop. As part of this challenge, we were to predict the outliers for an unlabeled network dataset, and then submit our labels to an API that the Julius Bär team had set up for the session. The challenge was gamified further by rewarding true positive submissions with 500 points and deducting 25 points for false positive submissions by the participants, to reflect both the high value of a true positive in a fraud detection context, while also underscoring the comparatively low, yet still relevant cost of false positives. My personal strategy for this challenge was to ensemble a number of unsupervised learning algorithms using justifiable hyperparameter values, as the time to train was relatively short for most algorithms we had been shown. With this approach, I managed to place in the top 10 of the circa 100-man workshop, which I was very pleased with given that the majority of my experience in the application of machine learning algorithms has been in supervised learning use-cases. At the end of the challenge, the top 3 teams were invited up to the stage and outlined their approaches to the challenge. Of these approaches, the general direction chosen by the top two was the most intriguing, as the contestants had first used a baseline approach to submit labels to the API, and then queried the API for which of their labels had been correct, an aspect of the challenge I had unfortunately overlooked at its outset. After this, the top two finishers used these labels to train supervised learning algorithms to find outliers in the rest of the data, thereby turning an unsupervised clustering task into a supervised classification task. While this was not a completely unsupervised approach, I was very impressed by the resourcefulness of the top two finishers and made a mental note to keep this strategy in mind should a similar use-case arise in which labels are not freely available or otherwise "expensive" to obtain.
This workshop was a great learning experience, due in large part to the clear explanations of the source material and organization of the session to optimize for engagement.

## From Forecasting to Prescriptive Analytics by KPMG
Another highlight from the workshop track of the Applied Machine Learning Days was the session hosted by KPMG, titled "From Forecasting to Prescriptive Analytics". In this talk, representatives from KPMG Analytics and Gurobi Optimization outlined the role that so-called "Prescriptive Analytics" can play in the lifecycle of an analytics project. In particular, Prescriptive Analytics was defined as the final step in the analytics process, in which the insights gathered from the predictive analytics stage are utilized in a way that can be converted into tangible decision "prescriptions". In this way, this workshop was diverged from the pure ML focus that characterized much of the rest of the conference, and provided for a welcome reminder that when approaching a business problem, it is crucial to not approach it like a boy with a hammer hunting for nails, and instead soberly evaluate possible tools for the job on the basis of their suitedness to the task. The tool that the talk outlined was Linear Programming, a tried and tested problem-solving framework borrowed from the field of Operations Research. The basis of this optimization paradigm is to define a problem mathematically in terms of an objective function, sets, parameters, variables and constraints, and then run a solving software (such as Gurobi Optimization, which was not so subtly suggested as *the* go-to solution for such use-cases) in order to find the provably optimal values of the previously defined variables. This way of solving problems is very different to the machine learning methods on display elsewhere at the conference, and prove to be highly useful in situations in which the problem to be solved is well-defined, but the permutation space of possible solutions is astronomically large. Common use cases for a Linear Programming appraoch include identifying optimal logistics routes, or planning the season schedule of sports teams. To the uninitiated, Linear Programming may on its face seem fairly simple, since "all" one does is define the problem at hand mathemtically; the difficult task of solving the actual optimization problem is left to one's solver of choice after all. However, as we quickly figured out in the challenge portion of the workshop, defining a fairly complicated problem is a difficult task all on its own, which requires both experience with Linear Programming and mathematical skill. Nonetheless, I thoroughly enjoyed gaining an insight into an entirely different side of algorithmic problem-solving, and will definitely make sure to sit down and try some Linear Programming again in the future.

# Conference Keynote Tracks

## Monday Evening Keynote with Michal Kosinski, Max Tegmark & Edward Snowden
Of the less technical sessions that were held at the Applied Machine Learning Days, the Monday Evening Keynote with Michal Kosinski, Max Tegmark & Edward Snowden was undoubtedly the most engaging. With its star-studded cast, the session drew a large audience at the end of a full day of machine learning talks, and luckily did not disappoint in its quality. While the final guest surely needs no introduction and inevitably elicited the most buzz at the conference before the event, Kosinski & Tegmark were also welcome speakers as heavyweights in the public discourse surrounding contemporary use of data and AI. 

Michal Kosinski, a Psychometrician and Associate Professor at Stanford University, is perhaps most well known for contributing the research that ultimately inspired what would become Cambridge Analytica's core product, the use of social media data to segment personality types and individualize political advertisements. In this way, even if you haven't directly heard of him, you have surely been made aware of his work, at least indirectly. After his presentation came that of Max Tegmark, a Professor of Physics at MIT, who shifted his research and publishing focus to Artificial Intelligence in recent years, and in doing so, has become a key public figure shaping the discourse of the field, in particular with respect to the existential risks that are associated with the advancement of Artificial Intelligence. The first two talks of the night, by the previously introduced speakers, were focused in particular on the current and future capabilities of AI, and the consequences that this will have for society at large. 

Kosinski first introduced his background of inspiring Cambridge Analytica's social media analytics approach to political advertising, and used this to highlight the fact that this approach was not novel upon its introduction, and not as difficult to operationalize as one might think, drawing parallels to how individuals can draw fairly accurate conclusions about individuals from sparse social data points. He then went on to discuss some newer work of his, which uses facial recognition to identify what are usually thought of as being latent personality traits, such as political leanings, extraversion or sexual orientation, with fairly high accuracy. While the use cases for Kosinki's research are frightening and must be handled carefully, the bottom line of his talk seemed to be the fact that we wear our personalities on our proverbial sleeves more than we may imagine.  

Max Tegmark's talk had a different leaning, with the focus being predominantly on how AI may develop and the problems it is causing even today. While making sure to assert the wonderful benefits that Machine learning in particular has afforded us in recent years, and will likely continue to do in the future, he stressed the need to proactively tackle issues such as autonomous systems, employment and superintelligence. While none of the worries he cited in this talk were novel, he raised an interesting possible approach, inspired by the field of Biology, to the mitigation of the malicious development of AI in the future. Tegmark made it clear that it is not impossible to establish clear moral delineations in a scientific field, as exemplified by the actions of biologists such as Professor Meselson, who played a major role in stopping the outright development of the US biological weapons program, as well as the culture of biologists in general, who routinely refuse to participate in the development of technology that could ostensibly be used to inflict harm on others. While I would hope that a similar approach would be possible in the field of AI, I am not particularly confident in a similar situation arising, largely due to the decentralized and highly democratized nature of the tools necessary to develop AI algorithms and the more impersonal nature of developing potentially harmful technology in AI as opposed to in Biology. Nonetheless, I believe that while it may be more difficult to cultivate such a culture (pun intended) in AI than in Biology, the example was useful and instructive for how members of a scientific field can take the matter of the ultimate use of their work into their own hands.


While not particularly focused on Machine Learning, Edward Snowden's talk was a personal highlight of the conference and an all-around surreal experience. Dialing in from Moscow, the world's most famous whistle-blower discussed data safety, the reality of the contemporary loss of our personal privacy and how machine learning can and will be used in the future to help expedite the process of mass surveillance. I did not take any notes during this talk, as I found myself in awe of Snowden's eloquence and gravitas (a term I rarely use to describe anyone), and decided that I would prefer to enjoy the experience instead of dissecting his words. What struck me in particular was how listening to him talk caused the entire mood of the auditorium to shift, no doubt due to our collective understanding and appreciation of his history, but also on account of his rhetorical talent. I was blown away by this talk, and hope to be able to revisit it soon via a recording.

## AI & Industry
As a Machine Learning practitioner currently in Industry, I attended this track as a way to get an overview of what approaches are being leveraged in this area, particularly within Switzerland. Among the speakers for this track included representativeness from Google, BCG, Credit Suisse,Swisscom, Roche and Atos, among others. The talks varied in length, depth and rigor, and I particularly enjoyed those of Google, BCG and Credit Suisse, primarily due to their practical focus and relative applicability to my own work and interests. 

The talk by Kristina Georgieva from BCG was titled "Testing your ML Pipelines", which was music to my ears as a great proponent of testing (it's saved me countless hours at my day job). The talk sought to counter the commonly heard narrative that machine learning software is inherently untestable due to its stochastic nature. What this perspective fails to take into account, however, is that a great deal of the code that is necessary to get to the point of inference (such as a data pipeline) is not stochastic, and as such an ideal candidate for unit and integration testing. While I did not need to be convinced by this talk, I was happy to see the issue be addressed at a conference that otherwise focuses very heavily on modelling.

Another talk that focused more on what surrounds the process of successfully bringing an ML system into production was given by Meghan Ruthven, a software engineer at Google. In her talk, she reiterated the Gartner result that 85% of machine learning projects do not succeed, and explained how, aside from operational factors, the disconnect between engineering and product mindsets can contribute to a machine learning project being likely to fail. She criticized the primary reliance on academic metrics such as AUC-ROC in machine learning teams, as while they may be indicative of model performance as it relates to the pre-defined goal, they do little to illuminate how end-users will interpret the models performance, or if the errors that it commits are uniquely detrimental to user's product experience. To combat this, she proposed measuring expected user satisfaction by creating prototypes with synthetic data and performing UX testing, which would allow you to get a clearer image of how your model will affect the user, and inform you of what may still need to be tweaked before deploying the model to production (such as speed of inference, for example). After this, she suggested iterating on your current model by using the insights from the UX testing for improvements, A/B testing the model and monitoring performance, and finally expanding the features once model performance is satisfactory. While this perspective is particularly relevant for those building machine learning products, and may not be relevant for all practitioners, it conveyed a sense of needing to be mindful of how you train your models and that one should make sure that when solving a problem using machine learning, the focus remains on the problem at hand, instead of on the synthetic metrics that are unlikely to be truly indicative of project success.

The final talk from this track that I would like to highlight was called "Outlier Detection using AlphaGan" by Constantin Nicolae of Credit Suisse. Having attended a fraud detection workshop only days earlier, I was excited to see how what we had done in our workshop can be extended and adapted to real world use cases. The approach discussed in the talk was demonstrated on a public credit card dataset from Kaggle, and made use of Autoencoders and Generative Adversarial Networks to create an outlier detection system they called AlphaGAN. Essentially, the crux of the system was to adapt the BiGAN model architecture, which augments a traditional GAN with an autoencoder. In the BiGAN, the famous game between the discriminator and generator is extended to have the discriminator not only choose between a real sample and synthetic sample given by the generator, but also between a real encoding (generated by the autoencoder) and a synthetic encoding (created by the Generator using the encodings from the Autoencoder). For a more in-depth explanation of the inner workings of BiGAN, check out this great article: https://towardsdatascience.com/using-bidirectional-generative-adversarial-networks-to-estimate-value-at-risk-for-market-risk-c3dffbbde8dd. According to Nicolae, where AlphaGAN extends the BiGAN is that the gradients learned by the Generator flow back to the autoencoder, which aids in the construction of the inlier data. After this, the approach take was to train the generator network to generate and reconstruct inlier data, and use the dicriminator to identify outliers within the test data. While I was already aware of how GANs are utilized in generation of synthetic media (such as video, images and audio), I was not aware of how their strengths can be leveraged to solve pressing industry use cases, such as fraud detection in financial institutions. 

## AI & NLP
A track that I could not miss at the Applied Machine Learning Days Conference was the one focusing on AI in Natural Language Processing (NLP). As of late, this subfield of ML research has bene gathering considerable excitement and interest, thanks in large part due to the effective leveraging of transfer learning and novel architectures, such as the Transformer (which underlies the famous GPT-2 and BERT models). Given the contemporary context and the breakneck pace at which NLP is evolving, this track was a personal "must-attend". 

The track can be split into two segments, namely the keynotes, focusing on state of the art results from research in NLP, and the spotlight presentations, which featured bite-sized presentations of applications of NLP in industry. With respect to the spotlight presentations, I particularly enjoyed those talks which focused on the details of implementations of machine-learning based solutions to NLP problems, as they gave a clear insight into how business problems are being solved in practice with this technology. A great example of such a talk was given by Ela Avrahami, representing Doodle. In her presentation, she outlined how Doodle's engineering team successfully combatted spamming on their website over a period of a few months. Interestingly enough, as the team first identified that the amount of spam on their website was rising, they first grabbed to high leverage, yet non-ML options, such as implementing reCaptchas and reducing posting limits. Once these were circumvented by the spammers, they looked to a machine-learning based approach by using an NLP classifier, powered by logistic regression. As they were dealing with a moving-target of sorts, they had to implement retraining and relabelling mechanisms such that the performance of their model did not degrade over time. While the solution and problem outlined in this talk are not novel, I enjoyed the temporal description of the development of this "war", as the speaker called it, as it revealed a number of insights into how to use machine learning effectively to solve business problems. Firstly, for many problems for which there are machine learning based solutions, there might be other possible measures that can be taken which could potentially help quell the issue (the implementation of reCaptchas and email limits in the Doodle example), but require little effort compared to the development and deployment of an additional machine learning system. Secondly, the approach by the team showed that in particular in time-critical situations, such as that of their siege by spammers, it is important to get an initial solution working to help control the situation, instead of instinctively grabbing the latest transformer model off the shelf and throwing it at your problem. Lastly, I thought the example-based explanation of their process in continuous fighting off of the spammers is a fantastic illustration of how models degrade over time. When the data on which you are performing inferences on is no longer sufficiently represented by the distribution of the data that it was trained on, the performance of your model will inevitably decrease. In the case of the spam war, one could not reasonably expect the deployed model to be able to accurately identify a post as spam if the spammers have somewhat caught on to what causes their posts to be blocked and altered their strategy. To effectively fight off these adaptations by the spammers, the model must clearly be retrained with posts using a new strategy to maintain the model's performance. While there were many other memorable applications of NLP explored by the various speakers of this track, I particularly enjoyed this talk for its insight into the peaks and troughs of a machine learning project, and the context that surrounds it.


The longer keynote presentations of the track focused on the enablement of NLU in many languages, the evolution of representations in transformers and cross-linguality and machine translation without bilingual data, by Prof. Roberto Navigli of Sapienza, Lena Voita of University of Edinburgh and Yandex Research, and Eneko Agirre of the University of the Basque Country, respectively. While all three were highly interesting accounts of current research on the cutting-edge of NLP, I was particularly impressed with the presentation given by Professor Agirre, who outlined his faculties' research into unsupervised machine translation. Through the course of his talk, Agirre progressively outlined iteration after iteration of approaches to machine translation, starting with the simple supervised approach, and at each step peeling off a crutch in the process to eventually land at an unsupervised neural machine translation approach utilizing self-learning. A memorable quote from the presentation is that the current performance of unsupervised machine translation approaches such as the one outlined in Agirre's talk are currently at the same level as supervised learning approaches were in 2014, despite the field only coming into existence in its own right in 2017. This is another instance showing the breakneck pace of development in machine learning as a whole, and is both highly inspiring and exciting for what the future may hold.
This talk blew away my conceptions of what is possible using machine learning based approaches. As a practitioner, in evaluating the solvability of certain problems, I am particularly biased by my knowledge of pre-existing approaches and the principles that underlie them in making my judgements. In this case, the depth of the research has shown that as you go deep into the theoretical foundations that underlie the algorithms we apply daily, there are fruits to be picked that defy the heuristically based reasoning about the limits of what machine learning can accomplish. I look forward to keeping an eye on the development of this field in particular.


All in all, the NLP track was both the most challenging and eye-opening that I attended at the conference, as it put a microscope to the specifics of the methods being used to advance the field that is currently capturing the imagination of a great deal of practitioners and researchers in the ML space. 

## Fazit
Attending the Applied Machine Learning Days was a fantastic experience, and I was happy to have the opportunity to expand my knowledge through praxis in the hands-on workshops, as well as feel the pulse of the current state of the art of the field in both research and industry through the keynotes and talks I attended. I would highly recommend anyone interested in Machine Learning living in Switzerland to attend!
